{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhen this is called using python train_model.py in the command line, this will \\ntake in the training dataset csv, \\nperform the necessary data cleaning and imputation, and \\nfit a classification model to the dependent Y. \\n\\nThere must be data check steps and clear commenting for each step inside the .py file. \\n\\nThe output for running this file is the random forest model saved as a .pkl file in the local directory. \\n\\nRemember that the thought process and decision for why you chose the final model \\nmust be clearly documented in this section. \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_model.py (5 points)\n",
    "\n",
    "\"\"\"\n",
    "When this is called using python train_model.py in the command line, this will \n",
    "take in the training dataset csv, \n",
    "perform the necessary data cleaning and imputation, and \n",
    "fit a classification model to the dependent Y. \n",
    "\n",
    "There must be data check steps and clear commenting for each step inside the .py file. \n",
    "\n",
    "The output for running this file is the random forest model saved as a .pkl file in the local directory. \n",
    "\n",
    "Remember that the thought process and decision for why you chose the final model \n",
    "must be clearly documented in this section. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# References: \n",
    "# https://ehackz.com/2018/03/23/python-scikit-learn-random-forest-classifier-tutorial/\n",
    "# https://stackoverflow.com/questions/55208734/save-lgbmregressor-model-from-python-lightgbm-package-to-disc\n",
    "# https://stackoverflow.com/questions/28199524/best-way-to-count-the-number-of-rows-with-missing-values-in-a-pandas-dataframe\n",
    "\n",
    "# packages\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import joblib\n",
    "    #from sklearn.preprocessing import OneHotEncoder\n",
    "    print(\"Packages loaded successfully.\")\n",
    "except:\n",
    "    print(\"One or more packages did not load correctly.  Please make sure all needed packages are installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# read in train data, validate\n",
    "#######################\n",
    "\n",
    "#read\n",
    "try:\n",
    "    df_train = pd.read_csv('train.csv')\n",
    "    print(\"Train data loaded succesfully.\")\n",
    "except:\n",
    "    print(\"Train data did NOT load successfully.  Please check that data is available, needed packages are installed, and functions are available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train is 891 rows x 12 columns\n",
    "#print(len(df_train) == 891)\n",
    "#print(len(df_train.columns) == 12)\n",
    "\n",
    "train_columns = (list(df_train.columns) == list(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']))\n",
    "#print(train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data imported correctly.\n"
     ]
    }
   ],
   "source": [
    "#set checkData condition\n",
    "checkData = (\n",
    "            (len(df_train) == 891) & \n",
    "            (len(df_train.columns) == 12) & \n",
    "            train_columns\n",
    "            )\n",
    "\n",
    "#print results\n",
    "if(checkData):\n",
    "    print(\"The train data imported correctly.\")\n",
    "else:\n",
    "    print(\"Error: the train data did NOT import correctly.  Please check the schema and contents of the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# data cleaning and imputation\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data successfully transformed with dummy columns.\n"
     ]
    }
   ],
   "source": [
    "#split categorical into dummy for model needs\n",
    "try:\n",
    "    df_train_sub = df_train[['Survived','Pclass', 'Age','Parch', 'Fare', 'Sex', 'SibSp', 'Embarked']] #select columns used for this model\n",
    "    df_train_d = pd.get_dummies(df_train_sub)\n",
    "    print(\"Train data successfully transformed with dummy columns.\")\n",
    "except:\n",
    "    print(\"Train data did not get dummy values correctly.  Please review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass   Age  Parch     Fare  SibSp  Sex_female  Sex_male  \\\n",
      "0           0       3  22.0      0   7.2500      1           0         1   \n",
      "1           1       1  38.0      0  71.2833      1           1         0   \n",
      "2           1       3  26.0      0   7.9250      0           1         0   \n",
      "3           1       1  35.0      0  53.1000      1           1         0   \n",
      "4           0       3  35.0      0   8.0500      0           0         1   \n",
      "..        ...     ...   ...    ...      ...    ...         ...       ...   \n",
      "886         0       2  27.0      0  13.0000      0           0         1   \n",
      "887         1       1  19.0      0  30.0000      0           1         0   \n",
      "888         0       3   NaN      2  23.4500      1           1         0   \n",
      "889         1       1  26.0      0  30.0000      0           0         1   \n",
      "890         0       3  32.0      0   7.7500      0           0         1   \n",
      "\n",
      "     Embarked_C  Embarked_Q  Embarked_S  \n",
      "0             0           0           1  \n",
      "1             1           0           0  \n",
      "2             0           0           1  \n",
      "3             0           0           1  \n",
      "4             0           0           1  \n",
      "..          ...         ...         ...  \n",
      "886           0           0           1  \n",
      "887           0           0           1  \n",
      "888           0           0           1  \n",
      "889           1           0           0  \n",
      "890           0           1           0  \n",
      "\n",
      "[891 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#show dummy data\n",
    "print(df_train_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Missing Data\n",
      "Survived        0\n",
      "Pclass          0\n",
      "Age           177\n",
      "Parch           0\n",
      "Fare            0\n",
      "SibSp           0\n",
      "Sex_female      0\n",
      "Sex_male        0\n",
      "Embarked_C      0\n",
      "Embarked_Q      0\n",
      "Embarked_S      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# impute missing values\n",
    "# in train data, only Age has missing values (177)\n",
    "print(\"Initial Missing Data\")\n",
    "print(df_train_d.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping NAs reduces rows from 891 to 714\n",
    "# too drastic\n",
    "# len(df_train_d.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation successfull.\n"
     ]
    }
   ],
   "source": [
    "#impute with median instead\n",
    "try:\n",
    "    df_train_d.fillna(df_train_d.median(), inplace=True)\n",
    "    print(\"Imputation successfull.\")\n",
    "except:\n",
    "    print(\"Imputation of missing values failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in df_train_d.\n"
     ]
    }
   ],
   "source": [
    "#validation: check for missing values after imputation\n",
    "try:\n",
    "    if(df_train_d.shape[0] - df_train_d.dropna().shape[0]) > 0:\n",
    "        print(\"Error: Missing values still exist in df_train_d.\")\n",
    "    else:\n",
    "        print(\"No missing values in df_train_d.\")\n",
    "except:\n",
    "    print(\"Error: check for missing values in df_train_d failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering: create CabinMissing column to capture this information\n",
    "df_train_d['CabinMissing'] = df_train['Cabin'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering: create categorical Pclass: 1, 2, 3\n",
    "# treat classes as categories and not as numeric\n",
    "df_train_d['Pclass_1'] = (df_train['Pclass']==1).astype(int)\n",
    "df_train_d['Pclass_2'] = (df_train['Pclass']==2).astype(int)\n",
    "df_train_d['Pclass_3'] = (df_train['Pclass']==3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# trains a random forest model on the training dataset using sklearn\n",
    "# fit a classification model to the dependent Y\n",
    "################################\n",
    "\n",
    "#set data/target columns\n",
    "# Note: excluded free text/many valued columns (Cabin, Name, Ticket).  \n",
    "# With more time would extract more information from them and use the extracted information in the model.\n",
    "data_cols = ['Pclass_1', 'Pclass_2','Pclass_3', 'Age', 'Parch', 'Fare', 'SibSp', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'CabinMissing']\n",
    "target_cols = ['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_d[data_cols]\n",
    "y = df_train_d[target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model train and test split step successfull.\n"
     ]
    }
   ],
   "source": [
    "#split into training/testing data\n",
    "# 30% split\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    print(\"Model train and test split step successfull.\")\n",
    "except:\n",
    "    print(\"Model train and test split step failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit and prediction step successfull.\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "try:\n",
    "    model = RandomForestClassifier(n_estimators = 100)\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_predict = model.predict(X_test)\n",
    "    print(\"Model fit and prediction step successfull.\")\n",
    "except:\n",
    "    print(\"Model fit and prediction step failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81       157\n",
      "           1       0.73      0.69      0.71       111\n",
      "\n",
      "    accuracy                           0.77       268\n",
      "   macro avg       0.76      0.76      0.76       268\n",
      "weighted avg       0.77      0.77      0.77       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report: print and save locally\n",
    "try:\n",
    "    classificationReport = classification_report(y_test.values, y_predict)\n",
    "    text_file = open(\"modelClassificationReport.txt\", \"w\")\n",
    "    text_file.write(classificationReport)\n",
    "    text_file.close()\n",
    "    print(\"Classifcation Report:\")\n",
    "    print(classificationReport)\n",
    "except:\n",
    "    print(\"Failed to output or save classification report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model succesfully saved locally.\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# Output for running this file is the random forest model saved as a .pkl file in the local directory\n",
    "######################################\n",
    "\n",
    "# save model\n",
    "try:\n",
    "    joblib.dump(model, 'model.pkl')\n",
    "    print(\"Model succesfully saved locally.\")\n",
    "except:\n",
    "    print(\"Error: model.pkl file not saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
