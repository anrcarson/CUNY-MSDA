{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhen this is called using python score_model.py in the command line, this will \\n\\ningest the .pkl random forest file and \\napply the model to the locally saved scoring dataset csv. \\n\\nThere must be data check steps and clear commenting for each step inside the .py file. \\n\\nThe output for running this file is a csv file with the predicted score, \\nas well as a png or text file output that contains the model accuracy report \\n(e.g. sklearn's classification report or any other way of model evaluation).\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score_model.py (2 points)\n",
    "\n",
    "\"\"\"\n",
    "When this is called using python score_model.py in the command line, this will \n",
    "\n",
    "ingest the .pkl random forest file and \n",
    "apply the model to the locally saved scoring dataset csv. \n",
    "\n",
    "There must be data check steps and clear commenting for each step inside the .py file. \n",
    "\n",
    "The output for running this file is a csv file with the predicted score, \n",
    "as well as a png or text file output that contains the model accuracy report \n",
    "(e.g. sklearn's classification report or any other way of model evaluation).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported correctly.\n"
     ]
    }
   ],
   "source": [
    "#packages\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import joblib\n",
    "    print(\"Packages imported correctly.\")\n",
    "except:\n",
    "    print(\"One or more packages did not load correctly.  Please make sure all needed packages are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded correctly.\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=None, min_impurity_split=1e-07,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\Anaconda2\\envs\\Python_37\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.18.1 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Andy\\Anaconda2\\envs\\Python_37\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.18.1 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "#ingest .pkl file\n",
    "####################\n",
    "\n",
    "#read in\n",
    "try:\n",
    "    model = joblib.load('model.pkl')\n",
    "    print(\"Model loaded correctly.\")\n",
    "except:\n",
    "    print(\"Error: Model failed to load.\")\n",
    "\n",
    "#check model loaded\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded correctly.\n",
      "     PassengerId  Pclass                                          Name  \\\n",
      "0            892       3                              Kelly, Mr. James   \n",
      "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                     Myles, Mr. Thomas Francis   \n",
      "3            895       3                              Wirz, Mr. Albert   \n",
      "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "..           ...     ...                                           ...   \n",
      "413         1305       3                            Spector, Mr. Woolf   \n",
      "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                           Ware, Mr. Frederick   \n",
      "417         1309       3                      Peter, Master. Michael J   \n",
      "\n",
      "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
      "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
      "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
      "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
      "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
      "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
      "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
      "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
      "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
      "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
      "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
      "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
      "\n",
      "[418 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# apply model to locally saved scoring dataset\n",
    "#############################\n",
    "\n",
    "#bring in data\n",
    "try:\n",
    "    df_test= pd.read_csv('test.csv')\n",
    "    print(\"Test data loaded correctly.\")\n",
    "except:\n",
    "    print(\"Test data did NOT load correctly.\")\n",
    "    \n",
    "#validate data\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test is 418 rows x 11 columns\n",
    "#print(len(df_test) == 418)\n",
    "#print(len(df_test.columns) == 11)\n",
    "\n",
    "test_columns = (list(df_test.columns) == list(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']))\n",
    "#print(test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test data imported correctly.\n"
     ]
    }
   ],
   "source": [
    "#set checkData condition\n",
    "checkData = (\n",
    "            (len(df_test) == 418) & \n",
    "            (len(df_test.columns) == 11) & \n",
    "            test_columns\n",
    "            )\n",
    "\n",
    "#print results\n",
    "if(checkData):\n",
    "    print(\"The test data imported correctly.\")\n",
    "else:\n",
    "    print(\"Error: the test data did NOT import correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data successfully transformed with dummy columns.\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# data cleaning and imputation - match same as training data\n",
    "###################################\n",
    "\n",
    "#split categorical into dummy\n",
    "try:\n",
    "    df_test_sub = df_test[['Pclass', 'Age','Parch', 'Fare', 'Sex', 'SibSp', 'Embarked']]\n",
    "    df_test_d = pd.get_dummies(df_test_sub)\n",
    "    print(\"Test data successfully transformed with dummy columns.\")\n",
    "except:\n",
    "    print(\"Test data did not get dummy values correctly.  Please review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass   Age  Parch      Fare  SibSp  Sex_female  Sex_male  Embarked_C  \\\n",
      "0         3  34.5      0    7.8292      0           0         1           0   \n",
      "1         3  47.0      0    7.0000      1           1         0           0   \n",
      "2         2  62.0      0    9.6875      0           0         1           0   \n",
      "3         3  27.0      0    8.6625      0           0         1           0   \n",
      "4         3  22.0      1   12.2875      1           1         0           0   \n",
      "..      ...   ...    ...       ...    ...         ...       ...         ...   \n",
      "413       3   NaN      0    8.0500      0           0         1           0   \n",
      "414       1  39.0      0  108.9000      0           1         0           1   \n",
      "415       3  38.5      0    7.2500      0           0         1           0   \n",
      "416       3   NaN      0    8.0500      0           0         1           0   \n",
      "417       3   NaN      1   22.3583      1           0         1           1   \n",
      "\n",
      "     Embarked_Q  Embarked_S  \n",
      "0             1           0  \n",
      "1             0           1  \n",
      "2             1           0  \n",
      "3             0           1  \n",
      "4             0           1  \n",
      "..          ...         ...  \n",
      "413           0           1  \n",
      "414           0           0  \n",
      "415           0           1  \n",
      "416           0           1  \n",
      "417           0           0  \n",
      "\n",
      "[418 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#show dummy data\n",
    "print(df_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Missing Data\n",
      "Pclass         0\n",
      "Age           86\n",
      "Parch          0\n",
      "Fare           1\n",
      "SibSp          0\n",
      "Sex_female     0\n",
      "Sex_male       0\n",
      "Embarked_C     0\n",
      "Embarked_Q     0\n",
      "Embarked_S     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# impute missing values\n",
    "# in test data, Age has missing values (86), and Fare (1)\n",
    "print(\"Initial Missing Data\")\n",
    "print(df_test_d.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data loaded succesfully for test data imputation.\n"
     ]
    }
   ],
   "source": [
    "#impute with medians from training data\n",
    "#read train data\n",
    "try:\n",
    "    df_train = pd.read_csv('train.csv')\n",
    "    print(\"Train data loaded succesfully for test data imputation.\")\n",
    "except:\n",
    "    print(\"Train data did NOT load successfully for test data imputation. Please check that data is available, needed packages are installed, and functions are available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation of missing values successfull.\n"
     ]
    }
   ],
   "source": [
    "#impute\n",
    "try:\n",
    "    df_test_d.fillna(df_train.median(), inplace=True)\n",
    "    print(\"Imputation of missing values successfull.\")\n",
    "except:\n",
    "    print(\"Imputation of missing values failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in df_test_d.\n"
     ]
    }
   ],
   "source": [
    "#validation: check for missing values after imputation\n",
    "try:\n",
    "    if(df_test_d.shape[0] - df_test_d.dropna().shape[0]) > 0:\n",
    "        print(\"Error: Missing values still exist in df_test_d.\")\n",
    "    else:\n",
    "        print(\"No missing values in df_test_d.\")\n",
    "except:\n",
    "    print(\"Error: check for missing values in df_test_d failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering: create CabinMissing column to capture this information\n",
    "df_test_d['CabinMissing'] = df_test['Cabin'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering: create categorical Pclass: 1, 2, 3\n",
    "# treat classes as categories and not as numeric\n",
    "df_test_d['Pclass_1'] = (df_test['Pclass']==1).astype(int)\n",
    "df_test_d['Pclass_2'] = (df_test['Pclass']==2).astype(int)\n",
    "df_test_d['Pclass_3'] = (df_test['Pclass']==3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data/target columns\n",
    "data_cols = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Age', 'Parch', 'Fare', 'SibSp', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S','CabinMissing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only include data for model\n",
    "X = df_test_d[data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction step successfull.\n"
     ]
    }
   ],
   "source": [
    "#make prediction\n",
    "try:\n",
    "    y_predict = model.predict(X)\n",
    "    print(\"Model prediction step successfull.\")\n",
    "except:\n",
    "    print(\"Error: model prediction on test data failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction output correct number of predictions.\n"
     ]
    }
   ],
   "source": [
    "#check length of prediction\n",
    "try:\n",
    "    if(len(y_predict)==418):\n",
    "        print(\"Model prediction output correct number of predictions.\")\n",
    "    else:\n",
    "        print(\"Model predicted failed to output correct number of predictions.\")\n",
    "except:\n",
    "    print(\"Error: model did NOT correctly output predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# output: csv file with predicted score\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored['Survived_Prediction'] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass                                          Name  \\\n",
      "0            892       3                              Kelly, Mr. James   \n",
      "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                     Myles, Mr. Thomas Francis   \n",
      "3            895       3                              Wirz, Mr. Albert   \n",
      "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "..           ...     ...                                           ...   \n",
      "413         1305       3                            Spector, Mr. Woolf   \n",
      "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                           Ware, Mr. Frederick   \n",
      "417         1309       3                      Peter, Master. Michael J   \n",
      "\n",
      "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \\\n",
      "0      male  34.5      0      0              330911    7.8292   NaN        Q   \n",
      "1    female  47.0      1      0              363272    7.0000   NaN        S   \n",
      "2      male  62.0      0      0              240276    9.6875   NaN        Q   \n",
      "3      male  27.0      0      0              315154    8.6625   NaN        S   \n",
      "4    female  22.0      1      1             3101298   12.2875   NaN        S   \n",
      "..      ...   ...    ...    ...                 ...       ...   ...      ...   \n",
      "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S   \n",
      "414  female  39.0      0      0            PC 17758  108.9000  C105        C   \n",
      "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n",
      "416    male   NaN      0      0              359309    8.0500   NaN        S   \n",
      "417    male   NaN      1      1                2668   22.3583   NaN        C   \n",
      "\n",
      "     Survived_Prediction  \n",
      "0                      0  \n",
      "1                      0  \n",
      "2                      0  \n",
      "3                      0  \n",
      "4                      0  \n",
      "..                   ...  \n",
      "413                    0  \n",
      "414                    1  \n",
      "415                    0  \n",
      "416                    0  \n",
      "417                    0  \n",
      "\n",
      "[418 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#validate assignment\n",
    "print(scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored file successfully saved locally.\n"
     ]
    }
   ],
   "source": [
    "#output\n",
    "try:\n",
    "    scored.to_csv('scored.csv',index=False)\n",
    "    print(\"Scored file successfully saved locally.\")\n",
    "except:\n",
    "    print(\"Scored file did NOT successfully save locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# output: png/text file with model accuracy report: sklearn classification report\n",
    "#############################################################################\n",
    "\n",
    "# Note: see train_model.py file for the code that supports this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
